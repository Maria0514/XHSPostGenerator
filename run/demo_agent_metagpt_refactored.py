"""
Streamlit + LangGraph ç‰ˆæœ¬çš„å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå™¨ï¼ˆé‡æ„ç‰ˆï¼‰
ä½¿ç”¨æ¨¡å—åŒ–çš„ Node ç»“æ„ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
"""

import os
import json
import re

# ç¦ç”¨ ChromaDB é¥æµ‹åŠŸèƒ½ï¼Œé¿å… telemetry æŠ¥é”™
os.environ["ANONYMIZED_TELEMETRY"] = "False"

from typing import Any, Dict, List
import streamlit as st
from streamlit_chat import message
from dotenv import load_dotenv
from tavily import TavilyClient

from spoil import TIANJI_PATH
from spoil.knowledges.langchain_onlinellm.models import SiliconFlowEmbeddings, SiliconFlowLLM
from langchain_chroma import Chroma
from langchain_core.documents import Document

# å¯¼å…¥é‡æ„åçš„æ¨¡å—
from spoil.spoil_agent import build_xhs_workflow
from spoil.spoil_agent.config import RAG_SCENE_MAP, SCENE_OPTIONS
from spoil.spoil_agent.spoilState import SpoilState

load_dotenv()


# --------------- åˆå§‹åŒ–èµ„æº ---------------

@st.cache_resource(show_spinner=False)
def get_embeddings():
    """è·å– Embedding æ¨¡å‹"""
    return SiliconFlowEmbeddings()


def build_retrievers(force: bool = False):
    """æ„å»ºå„åœºæ™¯çš„æ£€ç´¢å™¨"""
    embeddings = get_embeddings()
    retrievers: Dict[str, Any] = {}
    dest = os.path.join(TIANJI_PATH, "temp", "tianji-chinese")

    def _sanitize_jsonl_line(s: str) -> str:
        """å°†å¸¸è§çš„éæ³•æ§åˆ¶å­—ç¬¦è½¬ä¹‰æˆ JSON å¯è§£æå½¢å¼ã€‚

        å¸¸è§æ¥æºï¼šæŠŠæ–‡æ¡ˆç›´æ¥ç²˜è´´è¿› jsonlï¼Œé‡Œé¢å¤¹äº†çœŸå®çš„ Tab(\t) ç­‰æ§åˆ¶å­—ç¬¦ã€‚
        è¿™äº›å­—ç¬¦åœ¨ JSON å­—ç¬¦ä¸²é‡Œå¿…é¡»å†™æˆè½¬ä¹‰åºåˆ—ï¼ˆä¾‹å¦‚ \\tï¼‰ã€‚
        """
        # çœŸå®åˆ¶è¡¨ç¬¦ä¼šå¯¼è‡´ json.loads: Invalid control character
        s = s.replace("\t", "")
        # å…¶ä»–ä¸å¯è§æ§åˆ¶å­—ç¬¦ï¼ˆ0x00-0x1Fï¼Œä¿ç•™åˆæ³•ç©ºç™½å­—ç¬¦ 0x09/0x0A/0x0Dï¼‰ç»Ÿä¸€æ›¿æ¢ä¸ºç©ºæ ¼
        s = re.sub(r"[\x00-\x08\x0b\x0c\x0e-\x1f]", " ", s)
        return s
    
    if not os.path.exists(dest):
        from huggingface_hub import snapshot_download
        snapshot_download(
            repo_id="sanbu/tianji-chinese",
            local_dir=dest,
            repo_type="dataset",
            local_dir_use_symlinks=False,
            endpoint=os.environ.get("HF_ENDPOINT", None),
        )

    for scene_id, (_, folder) in RAG_SCENE_MAP.items():
        if folder is None:
            continue
        data_path = os.path.join(dest, "RAG", folder)
        if not os.path.exists(data_path):
            continue

        # jsonl-onlyï¼šæ¯ä¸ªåœºæ™¯ç›®å½•ä¸‹å›ºå®šæ”¾ç½® examples.jsonl
        jsonl_path = os.path.join(data_path, "examples.jsonl")
        if not os.path.exists(jsonl_path):
            print(f"æœªæ‰¾åˆ° jsonl è¯­æ–™ï¼Œè·³è¿‡ {data_path}ï¼ˆéœ€è¦ {jsonl_path}ï¼‰")
            continue
        persist = os.path.join(TIANJI_PATH, "temp", f"chromadb_{folder}")
        
        if os.path.exists(persist) and not force:
            vectordb = Chroma(persist_directory=persist, embedding_function=embeddings)
        else:
            if force and os.path.exists(persist):
                import shutil
                shutil.rmtree(persist)

            raw_docs: List[Document] = []
            try:
                with open(jsonl_path, "r", encoding="utf-8-sig") as f:
                    for line_no, line in enumerate(f, start=1):
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            obj = json.loads(_sanitize_jsonl_line(line))
                        except Exception as exc:
                            print(
                                f"jsonl è§£æå¤±è´¥ï¼Œè·³è¿‡ {jsonl_path}#L{line_no}ï¼š{type(exc).__name__}({exc})"
                            )
                            continue

                        text = (obj.get("text") or "").strip()
                        if not text:
                            continue

                        # Chroma metadata éœ€è¦æ‰å¹³çš„åŸºç¡€ç±»å‹ï¼Œé¿å…åµŒå¥— dict/list
                        metadata: Dict[str, Any] = {
                            "scene_id": str(obj.get("scene_id") or scene_id),
                            "id": str(obj.get("id") or f"{folder}-{line_no}"),
                            "type": str(obj.get("type") or "example"),
                            "source": jsonl_path,
                            "line": line_no,
                        }

                        if isinstance(obj.get("scene_name"), str) and obj.get("scene_name").strip():
                            metadata["scene_name"] = obj.get("scene_name").strip()

                        attrs = obj.get("attrs")
                        if isinstance(attrs, dict):
                            for k, v in attrs.items():
                                if isinstance(k, str) and isinstance(v, str) and v.strip():
                                    metadata[f"attr_{k}"] = v.strip()

                        tags = obj.get("tags")
                        if isinstance(tags, list):
                            tag_strs = [str(t).strip() for t in tags if str(t).strip()]
                            if tag_strs:
                                metadata["tags"] = "|".join(tag_strs[:20])

                        raw_docs.append(Document(page_content=text, metadata=metadata))
            except Exception as exc:
                print(f"åŠ è½½ jsonl è¯­æ–™å¤±è´¥ï¼Œè·³è¿‡ {jsonl_path}: {exc}")
                continue

            # ç¤ºä¾‹åº“æ¨¡å¼ï¼šä¸åšåˆ‡åˆ†ï¼Œä¿è¯å¬å›å°½é‡ä¸ºâ€œå®Œæ•´å•æ¡ç¤ºä¾‹â€
            docs = raw_docs
            
            if not docs:
                continue
            
            vectordb = Chroma.from_documents(
                documents=docs, embedding=embeddings, persist_directory=persist
            )

        # ä½¿ç”¨ MMR æå‡æ£€ç´¢å¤šæ ·æ€§ï¼Œå‡å°‘é‡å¤æ®µè½
        retrievers[scene_id] = vectordb.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 3, "fetch_k": 5},
        )
    
    return retrievers


# åˆå§‹åŒ–å…¨å±€èµ„æº
RAG_RETRIEVERS = build_retrievers(force=False)
TAVILY_KEY = os.getenv("TAVILY_API_KEY", "")
TAVILY_CLIENT = TavilyClient(api_key=TAVILY_KEY) if TAVILY_KEY else None

@st.cache_resource(show_spinner=False)
def get_app():
    """æ„å»ºå¹¶ç¼“å­˜å·¥ä½œæµ"""
    return build_xhs_workflow(RAG_RETRIEVERS, TAVILY_CLIENT)

APP = get_app()


# --------------- Streamlit UI ---------------
st.set_page_config(page_title="å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå™¨", page_icon="ğŸ’…ğŸ¼")

# åˆå§‹åŒ– session state
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
if "scene_label" not in st.session_state:
    st.session_state["scene_label"] = ""
if "scene_attributes" not in st.session_state:
    st.session_state["scene_attributes"] = {}
if "enable_se" not in st.session_state:
    st.session_state["enable_se"] = False
if "chat_completed" not in st.session_state:
    st.session_state["chat_completed"] = False


def reset_chat():
    """é‡ç½®å¯¹è¯"""
    st.session_state["chat_history"] = []
    st.session_state["scene_label"] = ""
    st.session_state["scene_attributes"] = {}


# ä¾§è¾¹æ 
with st.sidebar:
    st.markdown("## ğŸ“ æ”¯æŒçš„å†…å®¹ç±»å‹")
    for item in SCENE_OPTIONS:
        st.write(item)
    st.markdown("---")
    st.markdown("### ğŸ¯ å½“å‰å†…å®¹ç±»å‹")
    st.write(st.session_state["scene_label"])
    st.markdown("### ğŸ” æ–‡æ¡ˆå±æ€§")
    st.write(st.session_state["scene_attributes"])
    st.markdown("---")
    st.checkbox("ğŸŒ å¯ç”¨ç½‘ç»œæœç´¢ï¼ˆéœ€è¦ TAVILY_API_KEYï¼‰", key="enable_se")
    st.button("ğŸ”„ æ¸…ç©ºå¯¹è¯", on_click=reset_chat)

# ä¸»ç•Œé¢
st.title("âœ¨ å°çº¢ä¹¦æ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆå™¨")

# æ˜¾ç¤ºèŠå¤©å†å²
for idx, turn in enumerate(st.session_state["chat_history"]):
    if turn["role"] == "user":
        message(turn["content"], is_user=True, key=f"user_{idx}")
    else:
        message(turn["content"], is_user=False, key=f"assistant_{idx}")

# ç”¨æˆ·è¾“å…¥å¤„ç†
if user_input := st.chat_input("ğŸ’¡ å‘Šè¯‰æˆ‘ä½ æƒ³åˆ›ä½œä»€ä¹ˆæ ·çš„æ–‡æ¡ˆ..."):
    # å¦‚æœä¸Šä¸€ä¸ªå¯¹è¯å·²å®Œæˆï¼Œæ¸…ç©ºæ‰€æœ‰æ•°æ®å¼€å¯æ–°å¯¹è¯
    if st.session_state.get("chat_completed", False):
        st.session_state["chat_history"] = []
        st.session_state["scene_label"] = ""
        st.session_state["scene_attributes"] = {}
        st.session_state["chat_completed"] = False

    st.session_state["chat_history"].append({"role": "user", "content": user_input})
    
    init_state: SpoilState = {
        "user_input": user_input,
        "chat_history": st.session_state["chat_history"],
        "scene_label": st.session_state.get("scene_label", ""),
        "scene_attributes": st.session_state.get("scene_attributes", {}),
        "retrieved_docs": [],
        "search_enabled": st.session_state.get("enable_se", False),
        "search_queries": [],
        "search_results": {},
        "search_context": "",
        "final_answer": "",
        "need_more_info": False,
        "chat_completed": False,
    }
    
    message(user_input, is_user=True, key=f"user_{len(st.session_state['chat_history'])}")

    with st.spinner("æ€è€ƒä¸­..."):
        result = APP.invoke(init_state)

    if result.get("scene_label"):
        st.session_state["scene_label"] = result["scene_label"]
    if result.get("scene_attributes"):
        st.session_state["scene_attributes"] = result["scene_attributes"]

    assistant_text = result.get("final_answer", "")
    if assistant_text:
        if result.get("chat_completed") is True:
            st.session_state["chat_completed"] = True
        st.session_state["chat_history"].append({"role": "assistant", "content": assistant_text})
        message(assistant_text, is_user=False, key=f"assistant_{len(st.session_state['chat_history'])}")
        st.rerun()

    if result.get("need_more_info") and not assistant_text:
        fallback = "æˆ‘éœ€è¦æ›´å¤šåœºæ™¯è¦ç´ ï¼Œè¯·è¡¥å……ä¿¡æ¯ã€‚"
        st.session_state["chat_history"].append({"role": "assistant", "content": fallback})
        message(fallback, is_user=False, key=f"assistant_{len(st.session_state['chat_history'])}")
        st.rerun()