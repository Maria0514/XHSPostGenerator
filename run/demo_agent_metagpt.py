"""
Streamlit + LangGraph ç‰ˆæœ¬çš„å¤©æœºæ™ºèƒ½ä½“
å…¨éƒ¨æ”¹ä¸º LangChain/LangGraphï¼Œå®ç° RAGï¼ˆå‚è€ƒ demo_rag_langchain_all.pyï¼‰ä¸å¯é€‰è”ç½‘æœç´¢ã€‚
"""

from __future__ import annotations

import json
import os
from typing import Any, Dict, List, TypedDict

import streamlit as st
from dotenv import load_dotenv
from langgraph.graph import END, StateGraph
from tavily import TavilyClient
from tianji.knowledges.langchain_onlinellm.models import SiliconFlowEmbeddings, SiliconFlowLLM


from tianji import TIANJI_PATH
from tianji.agents.metagpt_agents.utils.helper_func import (
    extract_all_types,
    extract_all_types_and_examples,
    extract_attribute_descriptions,
    extract_single_type_attributes_and_examples,
    has_empty_values,
    is_number_in_types,
    load_json,
)
from tianji.knowledges.langchain_onlinellm.models import SiliconFlowLLM
try:
    from langchain_openai import OpenAIEmbeddings
except ImportError:
    from langchain_community.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader

load_dotenv()


class TianjiState(TypedDict):
    user_input: str
    chat_history: List[Dict[str, str]]
    scene_label: str
    scene_attributes: Dict[str, str]
    retrieved_docs: List[str]
    search_enabled: bool
    search_results: Dict[str, Any]
    final_answer: str
    need_more_info: bool


# --------------- å…¨å±€èµ„æº ---------------
SCENE_JSON = load_json("scene_attribute.json")
SCENE_OPTIONS = extract_all_types(SCENE_JSON)
SCENE_EXAMPLES = extract_all_types_and_examples(SCENE_JSON)

INTENT_PROMPT_TEMPLATE = """
#Role:
- åœºæ™¯åˆ†æåŠ©æ‰‹

## Background:
- ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„åœºæ™¯åˆ†æåŠ©æ‰‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºä¸€æ®µç”¨æˆ·ä¸å¤§æ¨¡å‹çš„å†å²å¯¹è¯è®°å½•ï¼Œuser è¡¨ç¤ºç”¨æˆ·ï¼Œassistant è¡¨ç¤ºå¤§æ¨¡å‹ï¼Œä½ éœ€è¦ä»ä¸­åˆ¤æ–­å¯¹è¯å±äºå“ªä¸ªåœºæ™¯ã€‚

## Goals:
- ä½ çš„ä»»åŠ¡æ˜¯å‡†ç¡®åˆ¤æ–­æœ€æ–°çš„ç”¨æˆ·æé—®ç¬¦åˆå“ªä¸ªåœºæ™¯ï¼Œç”¨æˆ·èº«å¤„åœ¨å“ªä¸ªåœºæ™¯ï¼Œç”¨æˆ·æƒ³è¦å¤§æ¨¡å‹æä¾›å“ªç§åœºæ™¯ä¸‹çš„å¸®åŠ©ã€‚

## Constraints:
- ä½ åªéœ€è¦ç”¨ä»£è¡¨åœºæ™¯æ ‡ç­¾çš„æ•°å­—å›å¤ï¼ˆä¾‹å¦‚åœºæ™¯æ ‡ç­¾æ˜¯"4ï¼šé€ç¥ç¦"ï¼Œåˆ™å›å¤æ•°å­— "4"ï¼‰ï¼Œä¸éœ€è¦å›å¤å…¶ä»–ä»»ä½•å†…å®¹ï¼
- ä½ éœ€è¦æ ¹æ®å†å²å¯¹è¯è®°å½•åˆ¤æ–­ç”¨æˆ·çš„åœºæ™¯æ˜¯å¦å‘ç”Ÿæ”¹å˜ï¼Œå¦‚æœæ˜¯ï¼Œå›å¤æœ€æ–°çš„åœºæ™¯å³å¯ã€‚
- å¦‚æœå†å²å¯¹è¯éƒ½ä¸ç¬¦åˆåœºæ™¯æ ‡ç­¾é€‰é¡¹ï¼Œè¯·åªè¿”å›å­—ç¬¦ä¸²"None"ã€‚
- ä½ æ— éœ€è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥è¿”å›ç­”æ¡ˆå³å¯ã€‚

## Inputs:
- å†å²å¯¹è¯è®°å½•ï¼š```{instruction}```
- åœºæ™¯æ ‡ç­¾é€‰é¡¹: ```{scene}```
- å…³äºåœºæ™¯æ ‡ç­¾é€‰é¡¹çš„ç»†åˆ†åœºæ™¯:```{scene_example}```
"""

REFINE_PROMPT_TEMPLATE = """
#Role:
- åœºæ™¯ç»†åŒ–å°åŠ©æ‰‹

## Background:
- ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„{scene}åœºæ™¯åˆ†æåŠ©æ‰‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºä¸€æ®µç”¨æˆ·ä¸å¤§æ¨¡å‹çš„å†å²å¯¹è¯è®°å½•ï¼Œuser è¡¨ç¤ºç”¨æˆ·ï¼Œassistant è¡¨ç¤ºå¤§æ¨¡å‹ï¼Œä½ éœ€è¦ä»ä¸­æå–ç›¸å¯¹åº”çš„åœºæ™¯è¦ç´ å¹¶ç»„è£…æˆjsonã€‚

## Goals:
- æˆ‘å°†æä¾›ç»™ä½ éœ€è¦æå–çš„åœºæ™¯è¦ç´ ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä»å†å²å¯¹è¯è®°å½•ä¸­çš„å†…å®¹åˆ†æå¹¶æå–å¯¹åº”åœºæ™¯çš„åœºæ™¯è¦ç´ ã€‚

## Constraints:
- åªè¿”å›å•ä¸ª json å¯¹è±¡ï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚
- å¦‚æœæ²¡æœ‰æå–åˆ°å¯¹åº”çš„åœºæ™¯è¦ç´ è¯·ç”¨ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼š"å¯¹è±¡è§’è‰²": ""ã€‚
- å¦‚æœå‘ç°åœºæ™¯è¦ç´ å‘ç”Ÿæ›´æ–°ï¼Œè¦†ç›–æ—§å€¼ã€‚

## Input:
- å†å²å¯¹è¯è®°å½•ï¼š```{instruction}```
- éœ€è¦æå–çš„åœºæ™¯è¦ç´ : ```{scene_attributes}```
- æ¯ä¸ªåœºæ™¯è¦ç´ çš„æè¿°ä»¥åŠä¾‹å­:```{scene_attributes_description}```
"""

QUESTION_PROMPT_TEMPLATE = """
#Role:
- æé—®å°åŠ©æ‰‹

## Goals:
- ç»™å‡ºé’ˆå¯¹ç©ºç¼ºåœºæ™¯è¦ç´ çš„å•ä¸ªè¿½é—®ã€‚

## Constraints:
- å¦‚æœæ‰€æœ‰åœºæ™¯è¦ç´ éƒ½æœ‰å€¼ï¼Œå›å¤å­—ç¬¦ä¸²"Full"ã€‚
- åªé—®ä¸€ä¸ªé—®é¢˜ã€‚

## Input:
- ç”¨æˆ·é¢å¯¹çš„åœºæ™¯ï¼š```{scene}```
- å½“å‰åœºæ™¯è¦ç´ : ```{scene_attributes}```
- æ¯ä¸ªåœºæ™¯è¦ç´ çš„æè¿°ä»¥åŠä¾‹å­:```{scene_attributes_description}```
"""

ANSWER_PROMPT_TEMPLATE = """
#Role:
- {scene}å°åŠ©æ‰‹

## Goals:
- æ ¹æ®åœºæ™¯è¦ç´ ã€æ£€ç´¢åˆ°çš„ RAG ç‰‡æ®µå’Œæœç´¢ç»“æœï¼Œç»“åˆå†å²å¯¹è¯ï¼Œç»™å‡ºå®šåˆ¶åŒ–å›ç­”ã€‚

## Constraints:
- éœ€è¦åŸºäºæä¾›çš„åœºæ™¯è¦ç´ ä¸ä¸Šä¸‹æ–‡è¿›è¡Œè¯¦ç»†å›ç­”ï¼Œé¿å…æ³›æ³›è€Œè°ˆã€‚
- å¦‚æœæœç´¢ç»“æœä¸ä¸ºç©ºï¼Œä¼˜å…ˆåŸºäºæœç´¢å†…å®¹ï¼›è‹¥ä¸ºç©ºï¼Œåˆ™ç»“åˆ RAG ç»“æœï¼›éƒ½ä¸ºç©ºå†ç”¨å¸¸è¯†è¡¥å……ã€‚

## Input:
- å†å²å¯¹è¯è®°å½•ï¼š```{history}```
- åœºæ™¯è¦ç´ : ```{scene_attributes}```
- RAG ä¸Šä¸‹æ–‡ï¼š```{rag_context}```
- æœç´¢ç»“æœï¼š```{search_context}```
"""


RAG_SCENE_MAP = {
    "1": ("æ•¬é…’ç¤¼ä»ªæ–‡åŒ–", "1-etiquette"),
    "2": ("è¯·å®¢ç¤¼ä»ªæ–‡åŒ–", "2-hospitality"),
    "3": ("é€ç¤¼ç¤¼ä»ªæ–‡åŒ–", "3-gifting"),
    "4": ("é€ç¥ç¦", None),
    "5": ("å¦‚ä½•è¯´å¯¹è¯", "5-communication"),
    "6": ("åŒ–è§£å°´å°¬åœºåˆ", "6-awkwardness"),
    "7": ("çŸ›ç›¾ä¸å†²çªåº”å¯¹", "7-conflict"),
}


@st.cache_resource(show_spinner=False)
def get_llm():
    return SiliconFlowLLM()


@st.cache_resource(show_spinner=False)
def get_embeddings():
    return SiliconFlowEmbeddings()


def format_history(history: List[Dict[str, str]]) -> str:
    return str(history)


def _sanitize_json(text: str) -> str:
    return (
        text.replace("```json", "")
        .replace("```", "")
        .replace("â€œ", '"')
        .replace("â€", '"')
        .replace("ï¼Œ", ",")
        .strip()
    )


def ensure_scene_attributes(scene_label: str, current: Dict[str, str]) -> Dict[str, str]:
    if scene_label and current:
        return current
    scene, attrs, _ = extract_single_type_attributes_and_examples(SCENE_JSON, scene_label)
    if not attrs:
        return current
    return {attr: current.get(attr, "") for attr in attrs}


def build_retrievers(chunk_size: int = 896, force: bool = False):
    embeddings = get_embeddings()
    retrievers: Dict[str, Any] = {}
    dest = os.path.join(TIANJI_PATH, "temp", "tianji-chinese")
    if not os.path.exists(dest):
        # å¤ç”¨ demo_rag_langchain_all.py çš„ä¸‹è½½é€»è¾‘
        from huggingface_hub import snapshot_download
        snapshot_download(
            repo_id="sanbu/tianji-chinese",
            local_dir=dest,
            repo_type="dataset",
            local_dir_use_symlinks=False,
            endpoint=os.environ.get("HF_ENDPOINT", None),
        )

    for scene_id, (_, folder) in RAG_SCENE_MAP.items():
        if folder is None:
            continue
        data_path = os.path.join(dest, "RAG", folder)
        if not os.path.exists(data_path):
            continue
        persist = os.path.join(TIANJI_PATH, "temp", f"chromadb_{folder}")
        if os.path.exists(persist) and not force:
            vectordb = Chroma(persist_directory=persist, embedding_function=embeddings)
        else:
            if force and os.path.exists(persist):
                import shutil

                shutil.rmtree(persist)
            loader = DirectoryLoader(
                data_path,
                glob="*.txt",
                loader_cls=TextLoader,
                loader_kwargs={"encoding": "utf-8"},
            )
            splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size, chunk_overlap=200
            )
            try:
                docs = splitter.split_documents(loader.load())
            except Exception as exc:
                print(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥ï¼Œè·³è¿‡ {data_path}: {exc}")
                continue
            if not docs:
                continue
            vectordb = Chroma.from_documents(
                documents=docs, embedding=embeddings, persist_directory=persist
            )
        retrievers[scene_id] = vectordb.as_retriever()
    return retrievers


RAG_RETRIEVERS = build_retrievers()
LLM = get_llm()
TAVILY_KEY = os.getenv("TAVILY_API_KEY", "")
TAVILY_CLIENT = TavilyClient(api_key=TAVILY_KEY) if TAVILY_KEY else None


def llm_invoke(prompt: str):
    if hasattr(LLM, "invoke"):
        return LLM.invoke(prompt)
    if hasattr(LLM, "_call"):
        return LLM._call(prompt)
    return LLM(prompt)


# --------------- LangGraph èŠ‚ç‚¹å®ç° ---------------
def intent_node(state: TianjiState):
    prompt = INTENT_PROMPT_TEMPLATE.format(
        instruction=format_history(state["chat_history"]),
        scene=SCENE_OPTIONS,
        scene_example=SCENE_EXAMPLES,
    )
    rsp = llm_invoke(prompt)
    intent = rsp if isinstance(rsp, str) else getattr(rsp, "content", str(rsp))
    return {"scene_label": intent.strip()}


def refine_node(state: TianjiState):
    scene_label_raw = state.get("scene_label", "").strip()
    scene_label = scene_label_raw.split("ï¼š")[0]
    if not scene_label or scene_label == "None" or not scene_label.isdigit() or not is_number_in_types(
        SCENE_JSON, int(scene_label)
    ):
        return {"need_more_info": True, "final_answer": "è¯¥é—®é¢˜ä¸åœ¨æ”¯æŒçš„åœºæ™¯å†…ï¼Œè¯·æ¢ä¸ªæé—®ã€‚"}

    base_attrs = ensure_scene_attributes(scene_label, state.get("scene_attributes", {}))
    scene, _, _ = extract_single_type_attributes_and_examples(SCENE_JSON, scene_label)
    desc = extract_attribute_descriptions(SCENE_JSON, base_attrs)

    refine_prompt = REFINE_PROMPT_TEMPLATE.format(
        instruction=format_history(state["chat_history"]),
        scene=scene,
        scene_attributes=base_attrs,
        scene_attributes_description=desc,
    )
    refined_text = llm_invoke(refine_prompt)
    refined = refined_text if isinstance(refined_text, str) else getattr(refined_text, "content", "")
    merged = base_attrs
    try:
        parsed = json.loads(_sanitize_json(refined))
        merged = {**base_attrs, **parsed}
    except Exception:
        merged = base_attrs

    if has_empty_values(merged):
        question_prompt = QUESTION_PROMPT_TEMPLATE.format(
            scene=scene,
            scene_attributes=merged,
            scene_attributes_description=desc,
        )
        question = llm_invoke(question_prompt)
        q_content = question if isinstance(question, str) else getattr(question, "content", "")
        return {
            "scene_attributes": merged,
            "need_more_info": q_content.strip() != "Full",
            "final_answer": q_content if q_content.strip() != "Full" else "",
        }

    return {"scene_attributes": merged, "need_more_info": False}


def rag_node(state: TianjiState):
    scene_label = state.get("scene_label", "").split("ï¼š")[0].strip()
    retriever = RAG_RETRIEVERS.get(scene_label)
    docs = []
    if retriever:
        try:
            docs = retriever.invoke(state["user_input"]) or []
        except Exception:
            docs = []
    doc_texts = [d.page_content for d in docs][:5]
    return {"retrieved_docs": doc_texts}


def _generate_queries(state: TianjiState) -> List[str]:
    attrs = state.get("scene_attributes", {})
    base = state.get("user_input", "")
    scene_label = state.get("scene_label", "")
    queries = [base]
    extra_bits = [v for v in attrs.values() if v]
    if scene_label:
        queries.append(f"åœºæ™¯{scene_label} {base}")
    if extra_bits:
        queries.append(base + " " + " ".join(extra_bits[:3]))
    return queries


def search_node(state: TianjiState):
    if not TAVILY_CLIENT:
        return {"search_results": {}}
    queries = _generate_queries(state)
    results: Dict[str, Any] = {}
    for idx, q in enumerate(queries):
        try:
            resp = TAVILY_CLIENT.search(q, max_results=5)
            results[str(idx)] = resp.get("results", [])
        except Exception:
            results[str(idx)] = []
    return {"search_results": results}


def _format_rag_docs(docs: List[str]) -> str:
    if not docs:
        return ""
    return "\n\n".join(docs[:5])


def _format_search_results(results: Dict[str, Any]) -> str:
    if not results:
        return ""
    lines = []
    for _, items in results.items():
        for item in items:
            url = item.get("url") or item.get("link")
            content = item.get("content") or item.get("snippet") or ""
            title = item.get("title", "")
            lines.append(f"{title}\n{url}\n{content}")
    return "\n\n".join(lines[:5])


def answer_node(state: TianjiState):
    scene_label = state.get("scene_label", "").split("ï¼š")[0].strip()
    scene, _, _ = extract_single_type_attributes_and_examples(SCENE_JSON, scene_label)
    rag_ctx = _format_rag_docs(state.get("retrieved_docs", []))
    search_ctx = _format_search_results(state.get("search_results", {}))
    prompt = ANSWER_PROMPT_TEMPLATE.format(
        scene=scene,
        scene_attributes=state.get("scene_attributes", {}),
        rag_context=rag_ctx,
        search_context=search_ctx,
        history=format_history(state["chat_history"]),
    )
    rsp = llm_invoke(prompt)
    ans = rsp if isinstance(rsp, str) else getattr(rsp, "content", str(rsp))
    return {"final_answer": ans}


# --------------- LangGraph æ„å»º ---------------
def build_app():
    workflow = StateGraph(TianjiState)
    workflow.add_node("intent", intent_node)
    workflow.add_node("refine", refine_node)
    workflow.add_node("rag", rag_node)
    workflow.add_node("search", search_node)
    workflow.add_node("answer", answer_node)

    workflow.set_entry_point("intent")
    workflow.add_edge("intent", "refine")

    def after_refine(state: TianjiState):
        return END if state.get("need_more_info") else "rag"

    workflow.add_conditional_edges("refine", after_refine, {"rag": "rag", END: END})

    def after_rag(state: TianjiState):
        return "search" if state.get("search_enabled") else "answer"

    workflow.add_conditional_edges("rag", after_rag, {"search": "search", "answer": "answer"})
    workflow.add_edge("search", "answer")
    workflow.add_edge("answer", END)
    return workflow.compile()


APP = build_app()


# --------------- Streamlit UI ---------------
st.set_page_config(page_title="å¤©æœº LangGraph", page_icon="ğŸ¤–")

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
if "scene_label" not in st.session_state:
    st.session_state["scene_label"] = ""
if "scene_attributes" not in st.session_state:
    st.session_state["scene_attributes"] = {}
if "enable_se" not in st.session_state:
    st.session_state["enable_se"] = False


def reset_chat():
    st.session_state["chat_history"] = []
    st.session_state["scene_label"] = ""
    st.session_state["scene_attributes"] = {}


with st.sidebar:
    st.markdown("## æ”¯æŒåœºæ™¯")
    for item in SCENE_OPTIONS:
        st.write(item)
    st.checkbox("å¯ç”¨ç½‘ç»œæœç´¢ï¼ˆéœ€è¦ TAVILY_API_KEYï¼‰", key="enable_se")
    st.button("æ¸…ç©ºå¯¹è¯", on_click=reset_chat)

st.title("äººæƒ…ä¸–æ•…å¤§æ¨¡å‹ Â· LangGraph ç‰ˆ")

for turn in st.session_state["chat_history"]:
    with st.chat_message(turn["role"]):
        st.markdown(turn["content"])

if user_input := st.chat_input("è¯·è¾“å…¥é—®é¢˜"):
    st.session_state["chat_history"].append({"role": "user", "content": user_input})
    init_state: TianjiState = {
        "user_input": user_input,
        "chat_history": st.session_state["chat_history"],
        "scene_label": st.session_state.get("scene_label", ""),
        "scene_attributes": st.session_state.get("scene_attributes", {}),
        "retrieved_docs": [],
        "search_enabled": st.session_state.get("enable_se", False),
        "search_results": {},
        "final_answer": "",
        "need_more_info": False,
    }

    result = APP.invoke(init_state)

    if result.get("scene_label"):
        st.session_state["scene_label"] = result["scene_label"]
    if result.get("scene_attributes"):
        st.session_state["scene_attributes"] = result["scene_attributes"]

    assistant_text = result.get("final_answer", "")
    if assistant_text:
        st.session_state["chat_history"].append({"role": "assistant", "content": assistant_text})
        with st.chat_message("assistant"):
            st.markdown(assistant_text)

    if result.get("need_more_info") and not assistant_text:
        # æ²¡æœ‰é—®é¢˜æ–‡æœ¬æ—¶ç»™å‡ºå…œåº•æç¤º
        fallback = "æˆ‘éœ€è¦æ›´å¤šåœºæ™¯è¦ç´ ï¼Œè¯·è¡¥å……ä¿¡æ¯ã€‚"
        st.session_state["chat_history"].append({"role": "assistant", "content": fallback})
        with st.chat_message("assistant"):
            st.markdown(fallback)
