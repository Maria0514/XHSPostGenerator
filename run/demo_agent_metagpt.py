"""
Streamlit + LangGraph ç‰ˆæœ¬çš„å¤©æœºæ™ºèƒ½ä½“
å…¨éƒ¨æ”¹ä¸º LangChain/LangGraphï¼Œå®ç° RAGï¼ˆå‚è€ƒ demo_rag_langchain_all.pyï¼‰ä¸å¯é€‰è”ç½‘æœç´¢ã€‚
"""

from __future__ import annotations

import json
import os
from typing import Any, Dict, List, Optional, TypedDict

import streamlit as st
from streamlit_chat import message
from dotenv import load_dotenv
from langgraph.graph import END, StateGraph
from tavily import TavilyClient
from tianji.knowledges.langchain_onlinellm.models import SiliconFlowEmbeddings, SiliconFlowLLM, ZhipuLLM

import loguru
from tianji import TIANJI_PATH
from tianji.agents.metagpt_agents.utils.helper_func import (
    extract_all_types,
    extract_all_types_and_examples,
    extract_attribute_descriptions,
    extract_single_type_attributes_and_examples,
    has_empty_values,
    is_number_in_types,
    load_json,
)
from tianji.knowledges.langchain_onlinellm.models import SiliconFlowLLM
try:
    from langchain_openai import OpenAIEmbeddings
except ImportError:
    from langchain_community.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader

load_dotenv()

logger = loguru.logger


class TianjiState(TypedDict):
    user_input: str
    chat_history: List[Dict[str, str]]
    scene_label: str
    scene_attributes: Dict[str, str]
    retrieved_docs: List[str]
    search_enabled: bool
    search_results: Dict[str, Any]
    final_answer: str
    need_more_info: bool


# --------------- å…¨å±€èµ„æº ---------------
SCENE_JSON = load_json("scene_attribute.json")
SCENE_OPTIONS = extract_all_types(SCENE_JSON)
SCENE_EXAMPLES = extract_all_types_and_examples(SCENE_JSON)

INTENT_PROMPT_TEMPLATE = """
#Role: å°çº¢ä¹¦å†…å®¹åˆ†ç±»åŠ©æ‰‹

## ä»»åŠ¡ï¼š
æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«ç”¨æˆ·æƒ³è¦åˆ›ä½œçš„å°çº¢ä¹¦å†…å®¹ç±»å‹ã€‚

## å†…å®¹ç±»å‹ï¼š
1. ç”Ÿæ´»åˆ†äº« - æ—¥å¸¸è¶£äº‹ã€ç¾é£Ÿã€æ—…æ¸¸è§é—»
2. ç¾å¦†æŠ¤è‚¤ - äº§å“æµ‹è¯„ã€æŠ¤è‚¤ç»éªŒ
3. æ—¶å°šç©¿æ­ - æ­é…çµæ„Ÿã€é£æ ¼åˆ†äº«
4. è¿åŠ¨å¥åº· - å¥èº«è®­ç»ƒã€å‡è‚¥æ–¹æ³•
5. ç§‘æŠ€æ•°ç  - ç”µå­äº§å“ã€æ•°ç æ‘„å½±
6. éŸ³ä¹å½±è§† - éŸ³ä¹æ¨èã€ç”µè§†å‰§æ¨è
7. ä¹¦ç±é˜…è¯» - ä¹¦ç±æ¨èã€é˜…è¯»æ–¹æ³•
8. å® ç‰©ç”Ÿæ´» - å® ç‰©å…»æŠ¤ã€å® ç‰©çŸ¥è¯†

## çº¦æŸï¼š
- åªè¿”å›æ•°å­—ï¼ˆ1-8ï¼‰ï¼Œä¸éœ€è¦å…¶ä»–å†…å®¹
- å¦‚æœä¸ç¬¦åˆä»»ä½•ç±»å‹ï¼Œè¿”å›"None"

## è¾“å…¥ï¼š
ç”¨æˆ·è¾“å…¥ï¼š```{instruction}```
"""

REFINE_PROMPT_TEMPLATE = """
#Role: å°çº¢ä¹¦æ–‡æ¡ˆå±æ€§æå–åŠ©æ‰‹

## Background:
- ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„{scene}å†…å®¹åˆ›ä½œåŠ©æ‰‹ï¼Œä½ éœ€è¦ä»ç”¨æˆ·çš„éœ€æ±‚æè¿°ä¸­æå–åˆ›ä½œæ–‡æ¡ˆæ‰€éœ€çš„å…³é”®å±æ€§ã€‚

## Goals:
- ä»ç”¨æˆ·çš„å†å²å¯¹è¯ä¸­åˆ†æå¹¶æå–å°çº¢ä¹¦æ–‡æ¡ˆåˆ›ä½œæ‰€éœ€çš„æ‰€æœ‰å…³é”®è¦ç´ ï¼Œå½¢æˆç»“æ„åŒ–çš„å±æ€§ä¿¡æ¯ã€‚

## Constraints:
- åªè¿”å›å•ä¸ª json å¯¹è±¡ï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚
- å¦‚æœæ²¡æœ‰æå–åˆ°å¯¹åº”çš„å±æ€§è¯·ç”¨ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºï¼Œä¾‹å¦‚ï¼š"ç›®æ ‡å—ä¼—": ""ã€‚
- å¦‚æœå‘ç°å±æ€§å‘ç”Ÿæ›´æ–°ï¼Œç”¨æ–°å€¼è¦†ç›–æ—§å€¼ã€‚
- å±æ€§å€¼åº”è¯¥ç®€æ´æ˜äº†ï¼Œç”¨å…³é”®è¯è¡¨ç¤ºã€‚

## Input:
- ç”¨æˆ·çš„åˆ›ä½œéœ€æ±‚ï¼š```{instruction}```
- éœ€è¦æå–çš„å±æ€§: ```{scene_attributes}```
- æ¯ä¸ªå±æ€§çš„è¯¦ç»†è¯´æ˜:```{scene_attributes_description}```
"""

QUESTION_PROMPT_TEMPLATE = """
#Role: å°çº¢ä¹¦æ–‡æ¡ˆåˆ›ä½œåŠ©æ‰‹

## Goals:
- æ ¹æ®å½“å‰å·²æ”¶é›†çš„ä¿¡æ¯ï¼Œé’ˆå¯¹ç¼ºå¤±çš„å…³é”®å±æ€§æå‡ºä¸€ä¸ªè‡ªç„¶ã€å‹å¥½çš„è¿½é—®ã€‚

## Constraints:
- å¦‚æœæ‰€æœ‰å±æ€§éƒ½å·²å®Œæ•´ï¼Œå›å¤å­—ç¬¦ä¸²"Full"ã€‚
- åªæä¸€ä¸ªé—®é¢˜ï¼Œä½¿ç”¨è‡ªç„¶å¯¹è¯çš„è¯­æ°”ã€‚
- é—®é¢˜åº”è¯¥å¼•å¯¼ç”¨æˆ·æä¾›å…·ä½“ã€æœ‰ç”¨çš„ä¿¡æ¯ã€‚

## Input:
- æ–‡æ¡ˆç±»å‹ï¼š```{scene}```
- å½“å‰å·²æœ‰çš„å±æ€§: ```{scene_attributes}```
- å„å±æ€§çš„è¯¦ç»†è¯´æ˜:```{scene_attributes_description}```
"""

ANSWER_PROMPT_TEMPLATE = """
#Role: {scene}å†…å®¹åˆ›ä½œä¸“å®¶

## ä»»åŠ¡ï¼š
åŸºäºç”¨æˆ·éœ€æ±‚ã€åˆ›ä½œå±æ€§å’Œå‚è€ƒå†…å®¹ï¼Œä¸ºç”¨æˆ·åˆ›ä½œä¸€ç¯‡ä¼˜è´¨çš„å°çº¢ä¹¦æ–‡æ¡ˆã€‚

## åˆ›ä½œæŒ‡å—ï¼š
1. å¼€å¤´ç­–ç•¥ï¼šç”¨è¡¨æƒ…ç¬¦å·ã€é—®é¢˜ã€å¯¹æ¯”æˆ–æ•°æ®å¸å¼•æ³¨æ„åŠ›
2. å†…å®¹ç»„ç»‡ï¼šç»“åˆæ•…äº‹æ„Ÿå’Œå®ç”¨å¹²è´§ï¼Œé€»è¾‘æ¸…æ™°
3. ç»“å°¾äº’åŠ¨ï¼šæå‡ºé—®é¢˜ã€å‘èµ·æŠ•ç¥¨æˆ–è¯é¢˜è®¨è®ºï¼Œå¼•å‘è¯„è®º
4. æ–‡æ¡ˆé£æ ¼ï¼š
   - è¯­æ°”è¦ç¬¦åˆç›®æ ‡å—ä¼—çš„å®¡ç¾
   - é€‚å½“ä½¿ç”¨emojiå’Œè¯é¢˜æ ‡ç­¾ï¼ˆ#è¯é¢˜ï¼‰
   - é¿å…ç”Ÿç¡¬å¹¿å‘Šï¼Œè¦æœ‰çœŸå®æ„Ÿå’Œäº²è¿‘æ„Ÿ
5. å­—æ•°æ§åˆ¶ï¼š300-800å­—ä¹‹é—´

## Constraints:
- ä¸¥æ ¼éµå®ˆç”¨æˆ·æŒ‡å®šçš„æ–‡æ¡ˆé£æ ¼å’Œç›®æ ‡å—ä¼—
- å¦‚æœæœ‰æœç´¢ç»“æœï¼Œä¼˜å…ˆå‚è€ƒæœ€æ–°çƒ­ç‚¹ä¿¡æ¯
- ç»“åˆRAGå‚è€ƒæ–‡æ¡ˆçš„ä¼˜ç§€è¡¨è¾¾æ–¹å¼
- å†…å®¹è¦åŸåˆ›ï¼Œé¿å…ç›´æ¥å¤åˆ¶å‚è€ƒæ–‡æ¡ˆ
- ç¡®ä¿æ–‡æ¡ˆç¬¦åˆå°çº¢ä¹¦çš„å†…å®¹è§„èŒƒ

## Input:
- ç”¨æˆ·çš„åˆ›ä½œéœ€æ±‚ï¼š```{history}```
- æ–‡æ¡ˆå±æ€§ï¼ˆé£æ ¼ã€å—ä¼—ç­‰ï¼‰: ```{scene_attributes}```
- å‚è€ƒæ–‡æ¡ˆåº“å†…å®¹ï¼š```{rag_context}```
- å®æ—¶æœç´¢ç»“æœï¼š```{search_context}```
"""


RAG_SCENE_MAP = {
    "1": ("ç”Ÿæ´»åˆ†äº«", "1-lifestyle"),
    "2": ("ç¾å¦†æŠ¤è‚¤", "2-beauty"),
    "3": ("æ—¶å°šç©¿æ­", "3-fashion"),
    "4": ("è¿åŠ¨å¥åº·", "4-fitness"),
    "5": ("ç§‘æŠ€æ•°ç ", "5-tech"),
    "6": ("éŸ³ä¹å½±è§†", "6-entertainment"),
    "7": ("ä¹¦ç±é˜…è¯»", "7-reading"),
    "8": ("å® ç‰©ç”Ÿæ´»", "8-pets"),
}


def get_llm(model:Optional[str] = None):
    return ZhipuLLM(model)


@st.cache_resource(show_spinner=False)
def get_embeddings():
    return SiliconFlowEmbeddings()


def format_history(history: List[Dict[str, str]]) -> str:
    return str(history)


def _sanitize_json(text: str) -> str:
    return (
        text.replace("```json", "")
        .replace("```", "")
        .replace("â€œ", '"')
        .replace("â€", '"')
        .replace("ï¼Œ", ",")
        .strip()
    )


def ensure_scene_attributes(scene_label: str, current: Dict[str, str]) -> Dict[str, str]:
    if scene_label and current:
        return current
    scene, attrs, _ = extract_single_type_attributes_and_examples(SCENE_JSON, scene_label)
    if not attrs:
        return current
    return {attr: current.get(attr, "") for attr in attrs}


def build_retrievers(chunk_size: int = 896, force: bool = False):
    embeddings = get_embeddings()
    retrievers: Dict[str, Any] = {}
    dest = os.path.join(TIANJI_PATH, "temp", "tianji-chinese")
    if not os.path.exists(dest):
        # å¤ç”¨ demo_rag_langchain_all.py çš„ä¸‹è½½é€»è¾‘
        from huggingface_hub import snapshot_download
        snapshot_download(
            repo_id="sanbu/tianji-chinese",
            local_dir=dest,
            repo_type="dataset",
            local_dir_use_symlinks=False,
            endpoint=os.environ.get("HF_ENDPOINT", None),
        )

    for scene_id, (_, folder) in RAG_SCENE_MAP.items():
        if folder is None:
            continue
        data_path = os.path.join(dest, "RAG", folder)
        if not os.path.exists(data_path):
            continue
        persist = os.path.join(TIANJI_PATH, "temp", f"chromadb_{folder}")
        if os.path.exists(persist) and not force:
            vectordb = Chroma(persist_directory=persist, embedding_function=embeddings)
        else:
            if force and os.path.exists(persist):
                import shutil

                shutil.rmtree(persist)
            loader = DirectoryLoader(
                data_path,
                glob="*.txt",
                loader_cls=TextLoader,
                loader_kwargs={"encoding": "utf-8"},
            )
            splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size, chunk_overlap=200
            )
            try:
                docs = splitter.split_documents(loader.load())
            except Exception as exc:
                print(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥ï¼Œè·³è¿‡ {data_path}: {exc}")
                continue
            if not docs:
                continue
            vectordb = Chroma.from_documents(
                documents=docs, embedding=embeddings, persist_directory=persist
            )
        retrievers[scene_id] = vectordb.as_retriever()
    return retrievers


RAG_RETRIEVERS = build_retrievers()
LLM = get_llm()
TAVILY_KEY = os.getenv("TAVILY_API_KEY", "")
TAVILY_CLIENT = TavilyClient(api_key=TAVILY_KEY) if TAVILY_KEY else None


def llm_invoke(prompt: str):
    if hasattr(LLM, "invoke"):
        return LLM.invoke(prompt)
    if hasattr(LLM, "_call"):
        return LLM._call(prompt)
    return LLM(prompt)


# --------------- LangGraph èŠ‚ç‚¹å®ç° ---------------
def intent_node(state: TianjiState):
    prompt = INTENT_PROMPT_TEMPLATE.format(
        instruction=format_history(state["chat_history"]),
        scene=SCENE_OPTIONS,
        scene_example=SCENE_EXAMPLES,
    )
    rsp = llm_invoke(prompt)
    intent = rsp if isinstance(rsp, str) else getattr(rsp, "content", str(rsp))
    return {"scene_label": intent.strip()}


def refine_node(state: TianjiState):
    scene_label_raw = state.get("scene_label", "").strip()
    scene_label = scene_label_raw.split("ï¼š")[0]
    if not scene_label or scene_label == "None" or not scene_label.isdigit() or not is_number_in_types(
        SCENE_JSON, int(scene_label)
    ):
        st.warning("æ­¤æ¨¡å‹åªæ”¯æŒå›ç­”å…³äºäººæƒ…ä¸–æ•…çš„äº‹é¡¹ï¼Œå·²è°ƒç”¨ API ä¸ºä½ è¿›è¡Œå•è½®å›ç­”ã€‚")
        rsp = llm_invoke(prompt=state["user_input"])
        return {"need_more_info": True, "final_answer": rsp if isinstance(rsp, str) else getattr(rsp, "content", str(rsp))}

    base_attrs = ensure_scene_attributes(scene_label, state.get("scene_attributes", {}))
    scene, _, _ = extract_single_type_attributes_and_examples(SCENE_JSON, scene_label)
    desc = extract_attribute_descriptions(SCENE_JSON, base_attrs)

    refine_prompt = REFINE_PROMPT_TEMPLATE.format(
        instruction=format_history(state["chat_history"]),
        scene=scene,
        scene_attributes=base_attrs,
        scene_attributes_description=desc,
    )
    refined_text = llm_invoke(refine_prompt)
    refined = refined_text if isinstance(refined_text, str) else getattr(refined_text, "content", "")
    merged = base_attrs
    try:
        parsed = json.loads(_sanitize_json(refined))
        merged = {**base_attrs, **parsed}
    except Exception:
        merged = base_attrs

    if has_empty_values(merged):
        question_prompt = QUESTION_PROMPT_TEMPLATE.format(
            scene=scene,
            scene_attributes=merged,
            scene_attributes_description=desc,
        )
        question = llm_invoke(question_prompt)
        q_content = question if isinstance(question, str) else getattr(question, "content", "")
        return {
            "scene_attributes": merged,
            "need_more_info": q_content.strip() != "Full",
            "final_answer": q_content if q_content.strip() != "Full" else "",
        }

    return {"scene_attributes": merged, "need_more_info": False}


def rag_node(state: TianjiState):
    scene_label = state.get("scene_label", "").split("ï¼š")[0].strip()
    retriever = RAG_RETRIEVERS.get(scene_label)
    docs = []
    if retriever:
        try:
            docs = retriever.invoke(state["user_input"]) or []
        except Exception:
            docs = []
    doc_texts = [d.page_content for d in docs][:5]
    return {"retrieved_docs": doc_texts}


def _generate_queries(state: TianjiState) -> List[str]:
    attrs = state.get("scene_attributes", {})
    base = state.get("user_input", "")
    scene_label = state.get("scene_label", "")
    queries = [base]
    extra_bits = [v for v in attrs.values() if v]
    if scene_label:
        queries.append(f"åœºæ™¯{scene_label} {base}")
    if extra_bits:
        queries.append(base + " " + " ".join(extra_bits[:3]))
    return queries


def search_node(state: TianjiState):
    if not TAVILY_CLIENT:
        return {"search_results": {}}
    queries = _generate_queries(state)
    results: Dict[str, Any] = {}
    for idx, q in enumerate(queries):
        try:
            resp = TAVILY_CLIENT.search(q, max_results=5)
            results[str(idx)] = resp.get("results", [])
        except Exception:
            results[str(idx)] = []
    return {"search_results": results}


def _format_rag_docs(docs: List[str]) -> str:
    if not docs:
        return ""
    return "\n\n".join(docs[:5])


def _format_search_results(results: Dict[str, Any]) -> str:
    if not results:
        return ""
    lines = []
    for _, items in results.items():
        for item in items:
            url = item.get("url") or item.get("link")
            content = item.get("content") or item.get("snippet") or ""
            title = item.get("title", "")
            lines.append(f"{title}\n{url}\n{content}")
    return "\n\n".join(lines[:5])


def answer_node(state: TianjiState):
    scene_label = state.get("scene_label", "").split("ï¼š")[0].strip()
    scene, _, _ = extract_single_type_attributes_and_examples(SCENE_JSON, scene_label)
    rag_ctx = _format_rag_docs(state.get("retrieved_docs", []))
    search_ctx = _format_search_results(state.get("search_results", {}))
    prompt = ANSWER_PROMPT_TEMPLATE.format(
        scene=scene,
        scene_attributes=state.get("scene_attributes", {}),
        rag_context=rag_ctx,
        search_context=search_ctx,
        history=format_history(state["chat_history"]),
    )
    rsp = llm_invoke(prompt)
    ans = rsp if isinstance(rsp, str) else getattr(rsp, "content", str(rsp))
    st.session_state["chat_completed"] = True
    return {"final_answer": ans}


# --------------- LangGraph æ„å»º ---------------
@st.cache_resource(show_spinner=False)
def build_app():
    workflow = StateGraph(TianjiState)
    workflow.add_node("intent", intent_node)
    workflow.add_node("refine", refine_node)
    workflow.add_node("rag", rag_node)
    workflow.add_node("search", search_node)
    workflow.add_node("answer", answer_node)

    workflow.set_entry_point("intent")
    workflow.add_edge("intent", "refine")

    def after_refine(state: TianjiState):
        return END if state.get("need_more_info") else "rag"

    workflow.add_conditional_edges("refine", after_refine, {"rag": "rag", END: END})

    def after_rag(state: TianjiState):
        return "search" if state.get("search_enabled") else "answer"

    workflow.add_conditional_edges("rag", after_rag, {"search": "search", "answer": "answer"})
    workflow.add_edge("search", "answer")
    workflow.add_edge("answer", END)
    return workflow.compile()


APP = build_app()

# --------------- Streamlit UI ---------------
st.set_page_config(page_title="å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå™¨", page_icon="âœ¨")

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
if "scene_label" not in st.session_state:
    st.session_state["scene_label"] = ""
if "scene_attributes" not in st.session_state:
    st.session_state["scene_attributes"] = {}
if "enable_se" not in st.session_state:
    st.session_state["enable_se"] = False
if "chat_completed" not in st.session_state:
    st.session_state["chat_completed"] = False


def reset_chat():
    st.session_state["chat_history"] = []
    st.session_state["scene_label"] = ""
    st.session_state["scene_attributes"] = {}


with st.sidebar:
    st.markdown("## ğŸ“ æ”¯æŒçš„å†…å®¹ç±»å‹")
    for item in SCENE_OPTIONS:
        st.write(item)
    st.markdown("---")
    st.markdown("### ğŸ¯ å½“å‰å†…å®¹ç±»å‹")
    st.write(st.session_state["scene_label"])
    st.markdown("### ğŸ” æ–‡æ¡ˆå±æ€§")
    st.write(st.session_state["scene_attributes"])
    st.markdown("---")
    st.checkbox("ğŸŒ å¯ç”¨ç½‘ç»œæœç´¢ï¼ˆéœ€è¦ TAVILY_API_KEYï¼‰", key="enable_se")
    st.button("ğŸ”„ æ¸…ç©ºå¯¹è¯", on_click=reset_chat)

st.title("âœ¨ å°çº¢ä¹¦æ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆå™¨")

for idx, turn in enumerate(st.session_state["chat_history"]):
    if turn["role"] == "user":
        message(turn["content"], is_user=True, key=f"user_{idx}")
    else:
        message(turn["content"], is_user=False, key=f"assistant_{idx}")

if user_input := st.chat_input("ğŸ’¡ å‘Šè¯‰æˆ‘ä½ æƒ³åˆ›ä½œä»€ä¹ˆæ ·çš„æ–‡æ¡ˆ..."):
    logger.info(f"ç”¨æˆ·è¾“å…¥ï¼š{user_input}")
    logger.info(f"å†å²å¯¹è¯ï¼š{st.session_state['chat_history']}")
        # å¦‚æœä¸Šä¸€ä¸ªå¯¹è¯å·²å®Œæˆï¼Œæ¸…ç©ºæ‰€æœ‰æ•°æ®å¼€å¯æ–°å¯¹è¯
    if st.session_state.get("chat_completed", False):
        st.session_state["chat_history"] = []
        st.session_state["scene_label"] = ""
        st.session_state["scene_attributes"] = {}
        st.session_state["chat_completed"] = False

    st.session_state["chat_history"].append({"role": "user", "content": user_input})
    init_state: TianjiState = {
        "user_input": user_input,
        "chat_history": st.session_state["chat_history"],
        "scene_label": st.session_state.get("scene_label", ""),
        "scene_attributes": st.session_state.get("scene_attributes", {}),
        "retrieved_docs": [],
        "search_enabled": st.session_state.get("enable_se", False),
        "search_results": {},
        "final_answer": "",
        "need_more_info": False,
    }
    message(user_input, is_user=True, key=f"user_{len(st.session_state['chat_history'])}")

    with st.spinner("æ€è€ƒä¸­..."):
        result = APP.invoke(init_state)

    if result.get("scene_label"):
        st.session_state["scene_label"] = result["scene_label"]
    if result.get("scene_attributes"):
        st.session_state["scene_attributes"] = result["scene_attributes"]

    assistant_text = result.get("final_answer", "")
    if assistant_text:
        st.session_state["chat_history"].append({"role": "assistant", "content": assistant_text})
        message(assistant_text, is_user=False, key=f"assistant_{len(st.session_state['chat_history'])}")
        st.rerun()

    if result.get("need_more_info") and not assistant_text:
        fallback = "æˆ‘éœ€è¦æ›´å¤šåœºæ™¯è¦ç´ ï¼Œè¯·è¡¥å……ä¿¡æ¯ã€‚"
        st.session_state["chat_history"].append({"role": "assistant", "content": fallback})
        message(fallback, is_user=False, key=f"assistant_{len(st.session_state['chat_history'])}")
        st.rerun()